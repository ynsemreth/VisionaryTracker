from flask import Flask, render_template, Response
from algorithm.object_detector import YOLOv7
import cv2
from utils.detections import draw
import numpy as np
from flask_socketio import SocketIO

app = Flask(__name__)
socketio = SocketIO(app)

class VideoCamera(object):
    def __init__(self):
        self.video = cv2.VideoCapture(0)
        self.yolov7 = YOLOv7()
        self.yolov7.load('coco.weights', classes='coco.yaml', device='cpu')
        print('[+] Video takip ediliyor...\n')
    
    def __del__(self):
        self.video.release()
    
    def get_frame(self):
        ret, frame = self.video.read()
        if not ret:
            return None
        
        lines = {}
        arrow_lines = []
        arrow_line_length = 50
                
        detections = self.yolov7.detect(frame, track=True)
        detected_frame = frame
        for detection in detections:
            color = (np.random.randint(0,255), np.random.randint(0,255), np.random.randint(0,255))
            detection_details = {
                'id': detection.get('id', 'N/A'),
                'type': detection.get('class', 'unknown'),
            }
                
            if 'id' in detection:
                detection_id = detection['id']

                if detection_id not in lines:
                    detection['color'] = color
                    lines[detection_id] = {'points':[], 'arrows':[], 'color':color}
                else:
                    detection['color'] = lines[detection_id]['color']
                    
                lines[detection_id]['points'].append(np.array([detection['x'] + detection['width']/2, detection['y'] + detection['height']/2], np.int32))
                points = lines[detection_id]['points']

                if len(points) >= 2:
                    arrow_lines = lines[detection_id]['arrows']
                    if len(arrow_lines) > 0:
                        distance = np.linalg.norm(points[-1] - arrow_lines[-1]['end'])
                        if distance >= arrow_line_length:
                            start = np.rint(arrow_lines[-1]['end'] - ((arrow_lines[-1]['end'] - points[-1])/distance)*10).astype(int)
                            arrow_lines.append({'start':start, 'end':points[-1]})
                    else:
                        distance = 0
                        arrow_lines.append({'start':points[-2], 'end':points[-1]})
                        
        for line in lines.values():
            arrow_lines = line['arrows']
            for arrow_line in arrow_lines:
                detected_frame = cv2.arrowedLine(detected_frame, arrow_line['start'], arrow_line['end'], line['color'], 2, line_type=cv2.LINE_AA)
            
        frame = draw(detected_frame, detections)
        socketio.emit('detection', detection_details)
        _, jpeg = cv2.imencode('.jpg', frame)
        return jpeg.tobytes()

def gen(camera):
    while True:
        frame = camera.get_frame()
        if frame is not None:
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n\r\n')

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/video')
def video():
    return Response(gen(VideoCamera()),
                    mimetype='multipart/x-mixed-replace; boundary=frame')

if __name__ == '__main__':
    app.run(debug=True, threaded=True)
